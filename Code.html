
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
    <meta content="text/html; charset=windows-1252"
      http-equiv="Content-Type">
  <link rel="shortcut icon" href="images/1.jpg">
  <link rel="stylesheet" type="text/css" href="static/css/bootstrap.min.css">
  <link rel="stylesheet" type="text/css" href="static/css/main.css" media="screen,projection">
  <link rel="stylesheet" type="text/css" href="static/css/custom.css" media="screen,projection">
  <link rel="stylesheet" type="text/css" href="style2.css" />
    <title>Liang Zheng</title>
  </head>

  <body  >

		<style> 
		a{ text-decoration: none;} 
		</style>
      <div id="header">
       <table style="text-align: left; width: 80%;" cellspacing="2"
      cellpadding="2" border="0">
      <tbody>
        <tr>
          <td colspan="3" rowspan="1" style="vertical-align: top;"><span
              style="font-family: Arial;  font-size: 22px">
                  <a style="text-decoration:underline;" 
                    href="index.html"><font color=black>Home</font></a>&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;
&nbsp;
                 <a style="text-decoration:underline;" 
                href="people.html"><font color=black>People</font></a>&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;
&nbsp;
                <a style="text-decoration:underline;" 
                    href="Publication.html"><font color=black>Publications</font></a>
                  &nbsp; &nbsp; &nbsp; &nbsp; 
              <a style="text-decoration:underline;" 
                    href="Code.html"><font color=black>Code</font></a>
                  &nbsp; &nbsp; &nbsp; &nbsp; 
                  <a style="text-decoration:underline;" 
                    href="Datasets.html"><font color=black>Datasets</font></a>
                  &nbsp; &nbsp; &nbsp; &nbsp; <a style="text-decoration:underline;" 
                    href="Slides.html"><font color=black>Slides</font></a>
</div>
                  <br><br>
</table>
  
        <!--<div style="	padding: 0;
	width: 800px;
	margin: 0 0 0 40px;  font-size:10pt; color:black">-->
<HR style="border:1 solid #cecccc" width="100%" SIZE=1>




<div id="papers">
<h3><font size=4.5 face="Arial" color="blue"><font color=black>Person Re-identification</font></font></h3>
<span style="line-height:22px;">
    <ul>
        <td>
            We proposed the ID-discriminative Embedding (IDE) in <a href="https://arxiv.org/pdf/1610.02984"><font color=blue>[Arxiv 2016]</font></a> and <a href="https://link.springer.com/chapter/10.1007/978-3-319-46466-4_52"><font color=blue>[ECCV 2016]</font></a>,
            <a href="https://github.com/zhunzhong07/IDE-baseline-Market-1501"><font color=blue>[Code]</font></a>
            <iframe src="https://ghbtns.com/github-btn.html?user=zhunzhong07&repo=IDE-baseline-Market-1501&type=star&count=true" frameborder="0" scrolling="0" width="94px" height="20px"></iframe>.
            <br />
            Later, we introduced the Part-based Convolutional Baseline (PCB) in <a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Yifan_Sun_Beyond_Part_Models_ECCV_2018_paper.pdf"><font color=blue>[ECCV 2018]</font></a>,
            <a href="https://github.com/syfafterzy/PCB_RPP_for_reID"><font color=blue>[Code]</font></a>
            <iframe src="https://ghbtns.com/github-btn.html?user=syfafterzy&repo=PCB_RPP_for_reID&type=star&count=true" frameborder="0" scrolling="0" width="94px" height="20px"></iframe>.
            <br />
            A tiny, friendly, strong baseline <a href="https://github.com/layumi/Person_reID_baseline_pytorch"><font color=blue>[Code]</font></a>
            <iframe src="https://ghbtns.com/github-btn.html?user=layumi&repo=Person_reID_baseline_pytorch&type=star&count=true" frameborder="0" scrolling="0" width="94px" height="20px"></iframe>.
            <br />
            We studied the domain adaptive re-ID problem. A representatives work is CamStyle <a href="https://ieeexplore.ieee.org/abstract/document/8485427/"><font color=blue>[CVPR 2018, TIP 2019]</font></a>,
            <a href="https://github.com/zhunzhong07/CamStyle"><font color=blue>[Code]</font></a>
            <iframe src="https://ghbtns.com/github-btn.html?user=zhunzhong07&repo=CamStyle&type=star&count=true" frameborder="0" scrolling="0" width="94px" height="20px"></iframe>.
            <br />
        </td>

    </ul>
    <h3><font size=4.5 face="Arial" color="blue"><font color=black>Generative Models for Discriminative Learning</font></font></h3>
    <ul>
        <td>
            For style-level domain adaptation, we designed SPGAN for person re-ID <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Deng_Image-Image_Domain_Adaptation_CVPR_2018_paper.pdf"><font color=blue>[CVPR 2018]</font></a>,
            <a href="https://github.com/Simon4Yan/Learning-via-Translation"><font color=blue>[Code]</font></a>
            <iframe src="https://ghbtns.com/github-btn.html?user=Simon4Yan&repo=Learning-via-Translation&type=star&count=true" frameborder="0" scrolling="0" width="94px" height="20px"></iframe>.
            The GAN generated images are effective for discriminative learning.
            <br />
            We proposed DG-net to generate pedestrians with various appearances/structures to augment the real-world data in discriminative learning
            <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Zheng_Joint_Discriminative_and_Generative_Learning_for_Person_Re-Identification_CVPR_2019_paper.pdf"><font color=blue>[CVPR 2019]</font></a>,
            <a href="https://github.com/NVlabs/DG-Net"><font color=blue>[Code]</font></a>
            <iframe src="https://ghbtns.com/github-btn.html?user=NVlabs&repo=DG-Net&type=star&count=true" frameborder="0" scrolling="0" width="94px" height="20px"></iframe>.
            <br />
        </td>
    </ul>

    <h3><font size=4.5 face="Arial" color="blue"><font color=black>Multi-object Tracking</font></font></h3>
    <ul>
        <td>
            We designed an efficient MOT system with near real-time performance, named JDE
            <a href="https://arxiv.org/pdf/1909.12605"><font color=blue>[Arxiv 2019]</font></a>,
            <a href="https://github.com/Zhongdao/Towards-Realtime-MOT"><font color=blue>[Code]</font></a>
            <iframe src="https://ghbtns.com/github-btn.html?user=Zhongdao&repo=Towards-Realtime-MOT&type=star&count=true" frameborder="0" scrolling="0" width="94px" height="20px"></iframe>.
            <br />
            We also studied the inherent difference between re-ID and MTMCT, and proposed the locality aware appearance metric (LAAM)
            <a href="https://arxiv.org/pdf/1911.12037"><font color=blue>[Arxiv 2019]</font></a>,
            <a href="https://github.com/hou-yz/DeepCC-local"><font color=blue>[Code]</font></a>
            <iframe src="https://ghbtns.com/github-btn.html?user=hou-yz&repo=DeepCC-local&type=star&count=true" frameborder="0" scrolling="0" width="94px" height="20px"></iframe>.
            <br />
        </td>
    </ul>

    <h3><font size=4.5 face="Arial" color="blue"><font color=black>Data Augmentation</font></font></h3>
    <ul>
        <td>
            We introduced Random Erasing for data augmentation
            <a href="https://arxiv.org/pdf/1708.04896"><font color=blue>[AAAI 2020]</font></a>,
            <a href="https://github.com/zhunzhong07/Random-Erasing"><font color=blue>[Code]</font></a>
            <iframe src="https://ghbtns.com/github-btn.html?user=zhunzhong07&repo=Random-Erasing&type=star&count=true" frameborder="0" scrolling="0" width="94px" height="20px"></iframe>.
            <br />
            Random Erasing is effective in image classification such as <a href="https://github.com/zhunzhong07/Random-Erasing"><font color=blue>CIFAR</font></a>
            and <a href="https://github.com/rwightman/pytorch-image-models"><font color=blue>ImageNet</font></a>,
            and <a href="https://github.com/zhunzhong07/CamStyle"><font color=blue>re-ID</font></a>.
            <br />
            There are some important third-party implementations, such as 
            <a href="https://pytorch.org/docs/master/torchvision/transforms.html#torchvision.transforms.RandomErasing"><font color=blue>Official Torchvision</font></a> and
            <a href="http://augmentor.readthedocs.io/en/master/code.html#Augmentor.Pipeline.Pipeline.random_erasing"><font color=blue>Python Augmentor</font></a>.
            <br />
            <br />
        </td>
    </ul>

    <h3><font size=4.5 face="Arial" color="blue"><font color=black>Domain Adaptive Semantic Segmentation</font></font></h3>
    <ul>
        <td>
            We released the code for CLAN, a category-level alignment method
            <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Luo_Taking_a_Closer_Look_at_Domain_Shift_Category-Level_Adversaries_for_CVPR_2019_paper.pdf"><font color=blue>[CVPR 2019]</font></a>,
            <a href="https://github.com/RoyalVane/CLAN"><font color=blue>[Code]</font></a>
            <iframe src="https://ghbtns.com/github-btn.html?user=RoyalVane&repo=CLAN&type=star&count=true" frameborder="0" scrolling="0" width="94px" height="20px"></iframe>.
            <br />
            We also released our code for MMAN that uses the adversarial loss
            <a href="https://arxiv.org/abs/1807.08260"><font color=blue>[ECCV 2018]</font></a>,
            <a href="https://github.com/RoyalVane/MMAN"><font color=blue>[Code]</font></a>
            <iframe src="https://ghbtns.com/github-btn.html?user=RoyalVane&repo=MMAN&type=star&count=true" frameborder="0" scrolling="0" width="94px" height="20px"></iframe>.
            <br />
        </td>
        <br />
        <br />
        <br />
    </ul>

</span>
</div>
  </body>
</html>
