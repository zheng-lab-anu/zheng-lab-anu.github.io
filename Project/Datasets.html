<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
    <meta content="text/html; charset=windows-1252"
      http-equiv="Content-Type">
  <link rel="shortcut icon" href="images/1.jpg">
  <link rel="stylesheet" type="text/css" href="static/css/bootstrap.min.css">
  <link rel="stylesheet" type="text/css" href="static/css/main.css" media="screen,projection">
  <link rel="stylesheet" type="text/css" href="static/css/custom.css" media="screen,projection">
  <link rel="stylesheet" type="text/css" href="style2.css" />
    <title>Liang Zheng</title>
  </head>

  <body  >

		<style> 
		a{ text-decoration: none;} 
		</style>
      <div id="header">
       <table style="text-align: left; width: 100%;" cellspacing="2"
      cellpadding="2" border="0">
      <tbody>
        <tr>
          <td colspan="3" rowspan="1" style="vertical-align: top;"><span
              style="font-family: Arial;  font-size: 22px">
                  <a style="text-decoration:underline;" 
                    href="index.html"><font color=black>Home</font></a>&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;
&nbsp;
                <a style="text-decoration:underline;" 
                    href="Publication.html"><font color=black>Publications</font></a>
                  &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a style="text-decoration:underline;" 
                    href="Datasets.html"><font color=black>Datasets</font></a>
                  &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a style="text-decoration:underline;" 
                    href="Slides.html"><font color=black>Slides</font></a>
</div>
                  <br><br>
</table>
  
<HR style="border:1 solid #cecccc" width="100%" SIZE=1>

<div id="papers">
			<br /><font size=4.0 color="black"><strong>PersonX engine</strong></font>
			<br /><span style="line-height:22px;">
			
We will release PersonX soon. This is a data synthesis engine capable of generating persons under controllable 
environmental conditions. That is, the illumination, viewpoint, camera settings can be edited precisely. This engine
creates several subsets where standard re-id evaluation and domain adaptation evaluation are available. But importantly, it is used to assess the impact of environmental factors on the system accuracy.
<br /><br />

<div id="papers">
			<br /><font size=4.0 color="black"><strong>Market-1501 dataset</strong></font>
			<br /><span style="line-height:22px;">
			
			This dataset is collected and annotated in Tsinghua. It has 6 cameras, 1,501 IDs and a distractor set of 500k images. Only one train/test split is used. We also annotate the ID-level attributes for Market-1501.
			<br />
			<a href="Project/project_reid.html"><font color="blue">project page</font></a>
			<br />
			<a href="https://github.com/vana77/Market-1501_Attribute"><font color="blue">attributes</font></a>
			<br />
			<a href="./Project/state_of_the_art_market1501.html"><font color="blue">state of the art on Market-1501</font></a>
			<br />
			<a href="Project/state_of_the_art_500k.html"><font color="blue">state of the art on Market-1501+500k</font></a>
<br /><br />

			<font size=4.0 color="black"><strong>DukeMTMC-ReID dataset</strong></font>
			<br />
			This dataset is a subset of the <a href="http://vision.cs.duke.edu/DukeMTMC/details.html"><font color="blue">DukeMTMC tracking dataset</font></a>. It has 8 cameras, 1,404 IDs and one train/test split. The evalution protocol is similar to Market-1501. Benchmarking results of some recent methods have been collected. We also annotate the ID-level attributes for DukeMTMC-ReID.
			<br />
			<a href="https://github.com/layumi/DukeMTMC-reID_evaluation"><font color="blue">project page</font></a>	
			<br />
			<a href="https://github.com/vana77/DukeMTMC-attribute"><font color="blue">attributes</font></a>
			<br />		<br />
			
			<font size=4.0 color="black"><strong>CUHK03 dataset with new evaluation protocol</strong></font>
			<br />
			We have used a new evaluation protocol for the CUHK03 dataset. This protocol only has one train/test split instead of the previous 20 train/test splits. The training and testing sets have 767 and 700 IDs, respectively. 
			<br />
			<a href="https://github.com/zhunzhong07/person-re-ranking"><font color="blue">project page</font></a>
<br /><br />

			<font size=4.0 color="black"><strong>MARS dataset</strong></font>
			<br />
			This dataset is a video extension of Market-1501. It has 6 cameras and 1,261 IDs. Only one train/test split is used. 
			<br />
			<a href="Project/project_mars.html"><font color="blue">project page</font></a>
			<br />
			<a href="Project/state_of_the_art_mars.html"><font color="blue">state of the art on MARS</font></a>
			<br /></font></a>			
<br />			
			<font size=4.0 color="black"><strong>PRW dataset</strong></font>
			<br />
			This dataset is another extension of Market-1501. It provides 11,816 video frames. We draw a bounding box for all the pedestrians. We assign an ID (1-932) to most of them, and -2 to those whose IDs we do not know for sure. For this dataset, one should create a gallery by pedestrian detection and then evaluate person re-identification. Re-ID performance is closely related to detection performance. 
			<br />
			<a href="Project/project_prw.html"><font color="blue">project page</font></a>			
			<br />

</span>
			</div>
					<!--</div>--> 
					<br class="clearfix" />
				<!--</div>-->
				<br class="clearfix" />
			</div>
		</div>
<!-- 		<div id="footer"> 
			Last Update: Apr. 25, 2013 by Liang Zheng.
		</div> -->
	</body>

